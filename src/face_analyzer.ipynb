{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTCNN causes tensorflow warnings so we will want to disable them, in addition tesnorflow needs to be configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your GPU is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## student object\n",
    "In order to get attentiveness each face that is found creates a student object. inside the object are attributes that I will discuss later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    \n",
    "    def __init__(self, face, name):\n",
    "        self.face = face\n",
    "        self.name = name\n",
    "        self.box = face['box']\n",
    "        self.face_points = face['keypoints']\n",
    "        self.attention_points = (0,0)\n",
    "        self.attention_angle_list = []\n",
    "        self.mode_attention_angle = 0\n",
    "        self.attention_angle_per_frame = []\n",
    "        self.absent_from_frame = 0\n",
    "\n",
    "    @property\n",
    "    def update_face(self):\n",
    "       self.face = face\n",
    "       self.box = face['box']\n",
    "       self.face_points = face['keypoints']\n",
    "\n",
    "    @update_face.setter\n",
    "    def update_face(self, face):\n",
    "        self.face = face\n",
    "        self.box = face['box']\n",
    "        self.face_points = face['keypoints']\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"student('{}', '{}')\".format(self.box, self.name)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"student: {} attentiveness: {}\".format(self.name, self.attention_angle_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "in this section I will first show the main `student_attentiveness` function and show the functions it calls on inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_attentiveness():\n",
    "    \"\"\"gets the student attentiveness for the lecture\n",
    "\n",
    "    Returns:\n",
    "        a csv of attentiveness\n",
    "\n",
    "    \"\"\"\n",
    "    if os.name == 'posix':\n",
    "        delimiter = '/'\n",
    "    else: \n",
    "        delimiter = '\\\\'\n",
    "    \n",
    "    current_directory = os.getcwd()\n",
    "    data_directory = os.path.abspath(os.path.join(current_directory, os.pardir + delimiter + 'data'))\n",
    "    screenshot_directory = os.path.abspath(os.path.join(data_directory + delimiter + 'screenshot'))\n",
    "    list_of_files = sorted(os.listdir(screenshot_directory))\n",
    "    \n",
    "    for i in range(len(list_of_files)):\n",
    "        img = cv2.imread(screenshot_directory + delimiter + list_of_files[i])\n",
    "        # print(screenshot_directory + delimiter + list_of_files[i])\n",
    "        if i == 0:\n",
    "            student_list = initial_frame(img)\n",
    "        for student in student_list:\n",
    "            try:\n",
    "                next_frame = cv2.imread(screenshot_directory + delimiter + list_of_files[i+1])\n",
    "                find_student_next_frame(student, next_frame)\n",
    "                check_for_absent(student_list)\n",
    "            except IndexError:\n",
    "                break\n",
    "        find_new_students(student_list, next_frame)\n",
    "    classroom_angles = []            \n",
    "    for student in student_list:\n",
    "        get_mode_angle(student)\n",
    "        get_attention_per_frame(student)\n",
    "        classroom_angles.append(student.attention_angle_per_frame)\n",
    "\n",
    "    # TODO: fix this, its padding because sometimes the length of student attention angles arent the same\n",
    "    max_len = max(len(x) for x in classroom_angles) \n",
    "    for i in classroom_angles:\n",
    "        if len(i) != max_len:\n",
    "            i.append(0.6)\n",
    "    \n",
    "    \n",
    "    avg_across_lecture = np.mean(classroom_angles,axis=0)\n",
    "    abs_avg_lecture = [abs(x) for x in avg_across_lecture]\n",
    "    np.savetxt(data_directory + delimiter + 'attentiveness.csv', abs_avg_lecture, delimiter=',', header='attentiveness')\n",
    "    return student_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first determines what operating system you have. this is important to decide what delimiter to use. (not sure if this is necessary, I think you can just do this all with the os.path stuff). Then we get the data directory and the screenshot directory, this will be important for reading and writing files.\n",
    "\n",
    "next is the for loop that iterates through the sampled lecture. it starts by reading the first image and if it is the first iteration it goes and initializes the student with the `initial_frame` function which i will discuss now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_frame(img):\n",
    "    \"\"\"initializes student object\n",
    "\n",
    "    Args:\n",
    "       img: first image in directory\n",
    "\n",
    "    Returns:\n",
    "        list of student objects\n",
    "\n",
    "    \"\"\"\n",
    "    student_list = []\n",
    "    img_size = img.shape\n",
    "    faces = find_faces(img)\n",
    "    for i in range(len(faces)):\n",
    "        student_list.append(Student(faces[i],str(i)))\n",
    "\n",
    "    for student in student_list:\n",
    "        get_pose_direction(student,img)\n",
    "        get_angle(student)\n",
    "    return student_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial_frame takes an image and returns a list of student objects. first it initializes the list gets the image size and then finds the faces in the image using the `find_faces` function which we will look at right now and then come back to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(img):\n",
    "    \"\"\"\n",
    "    Find the faces in an image\n",
    "    \n",
    "    Args:\n",
    "        img : Image to find faces from\n",
    "   \n",
    "    Returns:\n",
    "        faces : list of dictionaries of faces with keypoints\n",
    "\n",
    "    \"\"\"\n",
    "    min_conf = 0.9\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pixels = np.asarray(img)\n",
    "\n",
    "    detector = MTCNN()\n",
    "\n",
    "    detected = detector.detect_faces(pixels)\n",
    "    faces = [i for i in detected if i['confidence'] >= min_conf]\n",
    "    return faces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes an image and returns a list of faces, it only gets the faces that have above 90% confidence. Now lets go back to the `initial_frame` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have the list of faces it starts to iterate through the faces assigning them to a student object with i being the student name. (student: 1, student: 2, etc.) after that it iterates through the student list and gets the pose and angle of the student by using the `get_pose_direction` and `get_angle` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_direction(student,im):\n",
    "    img_size = im.shape\n",
    "    focal_length = img_size[1]\n",
    "    center = (img_size[1]/2, img_size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype = \"double\"\n",
    "    )\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),             # Nose tip\n",
    "        (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "        (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "        (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "        (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "    ])\n",
    "    dist_coeffs = np.zeros((4,1))\n",
    "    image_points = np.array([\n",
    "        student.face_points['nose'],        \n",
    "        student.face_points['left_eye'],    \n",
    "        student.face_points['right_eye'],   \n",
    "        student.face_points['mouth_left'],  \n",
    "        student.face_points['mouth_right']  \n",
    "    ], dtype=\"double\")\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_UPNP)\n",
    "    \n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # for p in image_points:\n",
    "    #     cv2.circle(im, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1)\n",
    "      \n",
    "    student.attention_points = ((int(image_points[0][0]), int(image_points[0][1])),(int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found this algorithm [here](https://learnopencv.com/head-pose-estimation-using-opencv-and-dlib/) which does a better job explaining it than I do. it uses the keypoints on a face to determine where the student is facing. This function then returns two points, one at he tip of the nose and the other in the direction of where the student is facing. ![example](../Image/pose.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets take a look at the `get_angle` function from the `initial_frame` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(student):\n",
    "    \"\"\"gets the angle of the slope of the points (best we could do), appends that angle to angle list\n",
    "\n",
    "    Args:\n",
    "       student: thestudent working on\n",
    "    \"\"\"\n",
    "    attention_points = student.attention_points\n",
    "    try:\n",
    "        m = ((attention_points[1][1] - attention_points[0][1])/(attention_points[1][0] - attention_points[0][0]))\n",
    "        angle = int(math.degrees(math.atan(m)))\n",
    "        student.attention_angle_list.append(angle)\n",
    "    except ZeroDivisionError:\n",
    "        angle = -90\n",
    "        student.attention_angle_list.append(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes in two points found from the get_pose function and determines the angle. it then appends the angle to the student object. this will be used to analyze the attentiveness per frame. after this is called in the `initial_frame` function that function is done and returns the student_list to the `student_attentiveness` function which we will now go back to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After it initializes students it then iterates through the students list. it then starts to analyze the next frame in the lecture. from there it runs the `find_student_next_frame` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_student_next_frame(student,next_image):\n",
    "    \"\"\"finds student in next frame and updates student attributes\n",
    "\n",
    "    Args:\n",
    "       student: student object \n",
    "       next_image: image for next frame\n",
    "\n",
    "    \"\"\"\n",
    "    top_left_point = (student.face_points['left_eye'][0], student.face_points['left_eye'][1])\n",
    "    bottom_right_point = (student.face_points['mouth_right'][0], student.face_points['mouth_right'][1])\n",
    "    \n",
    "    student_box = extend_box(top_left_point, bottom_right_point, 50)\n",
    "    \n",
    "    mask = np.zeros(next_image.shape[:2], dtype=np.uint8)\n",
    "    mask[student_box[0][1]:student_box[1][1]+1,student_box[0][0]:student_box[1][0]+1] = 255\n",
    "    rect_img = cv2.bitwise_and(next_image,next_image,mask=mask)\n",
    "    \n",
    "    face = find_faces(rect_img)\n",
    "    if len(face) > 1:\n",
    "        # TODO(#17): find a way to decrease dx and call function again\n",
    "        #print(\"more faces\")\n",
    "        \n",
    "        # TODO: add noise here instead of zero\n",
    "        student.attention_angle_list.append(0)\n",
    "    if len(face) < 1:\n",
    "        #if no faceappend with noise\n",
    "        #print(\"no face\")\n",
    "        student.attention_angle_list.append(0)\n",
    "        student.absent_from_frame += 1\n",
    "            \n",
    "    if len(face) == 1:\n",
    "        student.update_face = face[0]\n",
    "        get_pose_direction(student,next_image)\n",
    "        get_angle(student)\n",
    "    \n",
    "    # cv2.imshow(\"focused student\", rect_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    #return student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a student object and a next image, it cuts down the image to only a region where the student was scene in the last frame and then finds the face from that cropped image to see if the student is still there. it creates a region to search for faces using the `extend_box` function (we will look at after this). the image is cropped using the extended region and then searches for faces in that region. if there is more than one face then we append the student attention angle list with noise. if there is no face we say the student is absent from the frame and increment by 1 (if it reaches 10 then the student is removed from the list, this is to take into account a student moving from one side of the classroom to the other) lastly if the face is exactly 1 then we update the pose and student angle.\n",
    "![image](../Image/cropped.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_box(top_left,bottom_right,dx):\n",
    "    \"\"\"gets a box from a face in order to crop image to look for face again\n",
    "\n",
    "    Args:\n",
    "       top_left:     point for top left\n",
    "       bottom_right: point for bottom_right\n",
    "       dx:           the new box size\n",
    "\n",
    "    Returns:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    top_left = (top_left[0] - dx, top_left[1] - dx)\n",
    "    bottom_right = ((bottom_right[0] + dx, bottom_right[1] + dx))\n",
    "    return (top_left, bottom_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the arguments this takes in is the left eye and the mouth right. it extends the box by 50 pixels. and returns a new region to scan for faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets go back to `student_attentiveness`, after it checks for student in next frame. it then checks if it was absent 10 times (I can see that reseting the counter might be important if the student is found in again) using the `check_for_absent` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_for_absent(student_list):\n",
    "    \"\"\"checks if student is missing for 10 frames and removes them\n",
    "\n",
    "    Args:\n",
    "       student_list: list of students\n",
    "\n",
    "    Returns:\n",
    "        list of students\n",
    "\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for student in student_list:\n",
    "        if student.absent_from_frame >= 10:\n",
    "            student_list.pop(i)\n",
    "            #print(\"removed student\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this takes in a student list. If the student in the student list has been absent from the region it is searching for in the `find_student_next_frame` for more than 10 times. it is safe to say that the student was either walking to their seat or has left the class room. in both of these cases it is good to remove them in order to get attentiveness score. Now lets go back to `student_attentiveness`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after all the known students have been analyzed, it is time to search for new students, this is to make sure the program didn't miss any or for students that arrive late. the students that arrive late will have their attention_angle_list filled with noise as they were not paying attention previously. it will do this with the `find_new_students` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_students(student_list, next_frame):\n",
    "    \"\"\"looks for new students and appends them to student_list\n",
    "\n",
    "    Args:\n",
    "       student_list: list of objects\n",
    "       next_frame: next image\n",
    "\n",
    "    Returns:\n",
    "        student_list\n",
    "\n",
    "    \"\"\"\n",
    "    faces = find_faces(next_frame)\n",
    "    for face in faces:\n",
    "        \n",
    "        found = False\n",
    "        top_left = face['keypoints']['left_eye']\n",
    "        bottom_right = face['keypoints']['mouth_right']\n",
    "        extended_top_left, extended_bottom_right = extend_box(top_left, bottom_right, 50)\n",
    "        \n",
    "        \n",
    "        for student in student_list:\n",
    "            img = next_frame.copy()\n",
    "            test_top_left = student.face_points['left_eye']\n",
    "            test_bottom_right = student.face_points['mouth_right']\n",
    "            \n",
    "            # cv2.circle(img, test_top_left,1,(0,0,255),2)\n",
    "            # cv2.circle(img, test_bottom_right,1,(0,0,255),2)\n",
    "            # cv2.rectangle(img, extended_top_left, extended_bottom_right, (255,255,0),1)\n",
    "            # cv2.imshow(\"newframe\", img)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            \n",
    "            if check_box(extended_top_left,extended_bottom_right,test_top_left,test_bottom_right):\n",
    "                found = True\n",
    "                #print(\"found\")\n",
    "                break\n",
    "            \n",
    "    \n",
    "        if found == False:\n",
    "            #print(\"added student\")\n",
    "            max_name = max([int(x.name) + 1 for x in student_list])\n",
    "            # TODO: instead of zero add noise\n",
    "            attention_list = [0 for i in range(len(student_list[0].attention_angle_list))]\n",
    "            student_list.append(Student(face,max_name))\n",
    "            student_list[-1].attention_angle_list = attention_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel like I can change this somehow. right now what the function iterates through the known students finds the ones it already knows and when it finds it, the loop just breaks. ive tried updating the student attributes when it finds the students from here before. but the issue is that it searches through the same image so many times that it would update the students a lot and produce results that are inaccurate. \n",
    "\n",
    "anyways i think that showing what this is doing through pictures is best. first it finds all the faces in the image. then it does the extend box thing that i talked about before. then it iterates through the student list and places the two points. if the two points are inside the box it knows that the student is already accounted for. otherwise it adds a new student. \n",
    "\n",
    "This student will be found. this first shows that face points are not in the box so the student is not found yet. the second picture the points are in the box so the student is found and will then move onto the next face.\n",
    "![not_found](../Image/student_not_found.png)\n",
    "![found](../Image/student_found.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next image shows a student that showed up late. they were not in the last frame but they are in the current one. they will be added to the student list.\n",
    "![will_not_be_found](../Image/will_not_be_found.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a function in `find_new_student` that i havent talked about yet, it is the `check_box` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_box(rect_top_left, rect_bottom_right, test_top_left, test_bottom_right):\n",
    "    \"\"\"checks if the face points are in the boxx\n",
    "\n",
    "    Args:\n",
    "       rect_top_left: box top left point\n",
    "       rect_bottom_right: box bottom right\n",
    "       test_top_left: student left eye \n",
    "       test_bottom_right: student mouth right\n",
    "\n",
    "    Returns:\n",
    "        bool if points are in box\n",
    "\n",
    "    \"\"\"\n",
    "    if (rect_top_left[0] < test_top_left[0]) and (rect_top_left[0] < test_bottom_right[0]) \\\n",
    "    and (rect_bottom_right[0] > test_top_left[0]) and (rect_bottom_right[0] > test_bottom_right[0]) \\\n",
    "    and (rect_top_left[1] < test_top_left[1]) and (rect_top_left[1] < test_bottom_right[1]) \\\n",
    "    and (rect_bottom_right[1] > test_top_left[1]) and (rect_bottom_right[1] > test_bottom_right[1]):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is pretty simple. the coordinates for images increase from left to right and increase from top to bottom. so in order to find if points are within a the parameters of the box the test are compared with against each other. \\[0\\] is the x position and \\[1\\] is the y position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we go back to `student_attentiveness`. once it analyzes all the files it iterates through the student list and does calculations on the attention angle. we (the group) made an assumption here, students are paying attention the majority of the time. so the program finds the mode angle. in order to do this the angles need to be rounded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode_angle(student):\n",
    "    \"\"\"gets the mode angle (students are assumed to be paying attention most of the time)\n",
    "\n",
    "    Args:\n",
    "       student: student object\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    angle_list = student.attention_angle_list\n",
    "    \n",
    "    # filter out value for zero\n",
    "    for i in range(len(angle_list)):\n",
    "        if abs(angle_list[i]) <= 2:\n",
    "            if angle_list[i] > 0:\n",
    "                angle_list[i] = 3\n",
    "            else:\n",
    "                angle_list[i] = -3\n",
    "            \n",
    "    binned = [5 * round(x/5) for x in angle_list]\n",
    "    mode = max(set(binned), key=binned.count)\n",
    "    student.mode_attention_angle = mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i dont want the mode angle to be 0 so i made it so that it will always round either to 5 or negative 5. now back to `student_attentiveness`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next function call is `get_attention_per_frame` which really just divides the attention at that frame by the mode angle to get a ratio of attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_per_frame(student):\n",
    "    \"\"\"gets the ratio of the attention at frame vs mode_attention_angle\n",
    "\n",
    "    Args:\n",
    "       student: student object\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    attention_list = student.attention_angle_list\n",
    "    mode_attention_angle = student.mode_attention_angle\n",
    "    student.attention_angle_per_frame = [x/mode_attention_angle for x in attention_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now back to `student_attentiveness` the last thing it does is pad the classroom angles. This is a bug in my code. somewhere it doesn't fill the attention_list all the way. all the ones that arent the same are off by one. i dont know where this is. so i need help finding so i dont have to pad it. lastly it gets the mean of the attention angles per frame for the whole classroom and that is what we are using for our attentiveness. I think this program is pretty much done i dont think i will change it too much in the future. I might fill the attention with actual noise instead of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from split_video import split\n",
    "    from analyze_video import screencap_video\n",
    "\n",
    "    # lecture = 'class1facingstudents.mov'\n",
    "    # split(lecture, 'students')\n",
    "    \n",
    "    # screencap_file = 'students-output-video.mp4'\n",
    "    # screencap_video(screencap_file)\n",
    "\n",
    "    student_list = student_attentiveness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorf",
   "language": "python",
   "name": "tensorf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
